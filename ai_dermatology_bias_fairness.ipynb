{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333329ee-112c-4f8b-b5e5-567aadd70446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ResNet Training Script (Fairness-Aware Eczema Diagnosis)\n",
    "# Author: Domante Rabasauskaite\n",
    "# Date: 09 April 2025\n",
    "# =============================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "from torch.nn.utils import prune\n",
    "from torch.quantization import quantize_dynamic\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Timestamp for saving outputs (e.g., models, plots)\n",
    "timestamp = \"05_05_2025\"\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1. HYPERPARAMETERS & DATA PATHS\n",
    "# ---------------------------------------------\n",
    "\n",
    "# DermNet pretraining parameters\n",
    "lr = 1e-5                        # Learning rate\n",
    "weight_decay = 1e-2             # L2 regularization\n",
    "dropout_rate = 0.2              # Dropout to prevent overfitting\n",
    "num_epochs_pretrain = 5         # Epochs for DermNet pretraining\n",
    "patience_pretrain = 2           # Early stopping patience\n",
    "\n",
    "# PASSION fine-tuning parameters\n",
    "fairness_lambda_passion = 0.1   # Weight for fairness loss term\n",
    "num_epochs_finetune = 15        # Epochs for PASSION fine-tuning\n",
    "patience_finetune = 3           # Early stopping patience for fine-tuning\n",
    "freeze_epochs_passion = 5       # Epochs with frozen base layers\n",
    "\n",
    "# File paths - replace with your actual locations\n",
    "dermnet_train_root = r\"C:\\Users\\DermNet\\train\"\n",
    "dermnet_unseen_root = r\"C:\\Users\\DermNet\\test\"  # Optional test folder\n",
    "\n",
    "passion_csv_path = r\"C:\\Users\\PASSION_MICCAI_2024\\label.csv\"\n",
    "passion_image_folder = r\"C:\\Users\\PASSION_MICCAI_2024\\images\"\n",
    "\n",
    "# Device setup: use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. PASSION CSV SPLITTING FOR CROSS-VALIDATION\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(\"Loading PASSION CSV...\")\n",
    "df_full = pd.read_csv(passion_csv_path)\n",
    "df_full.columns = df_full.columns.str.strip()  # Strip column names for consistency\n",
    "print(f\"PASSION CSV loaded: {len(df_full)} rows.\")\n",
    "\n",
    "# Use StratifiedGroupKFold to split while preserving condition balance and subject grouping\n",
    "print(\"Splitting PASSION dataset using StratifiedGroupKFold...\")\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in sgkf.split(df_full, df_full[\"conditions_PASSION\"], groups=df_full[\"subject_id\"]):\n",
    "    train_df = df_full.iloc[train_idx]\n",
    "    val_df = df_full.iloc[val_idx]\n",
    "    break  # Use only the first fold for this run\n",
    "\n",
    "# Save the split to CSV for reproducibility\n",
    "train_csv = \"train_split.csv\"\n",
    "val_csv = \"val_split.csv\"\n",
    "train_df.to_csv(train_csv, index=False)\n",
    "val_df.to_csv(val_csv, index=False)\n",
    "print(f\"PASSION split complete: {len(train_df)} training rows, {len(val_df)} validation rows.\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. IMAGE TRANSFORMATIONS (WITH DADA AUGMENTATION)\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(\"Defining image transformations...\")\n",
    "\n",
    "class DADATransform:\n",
    "    \"\"\"\n",
    "    Proxy for Differentiable Automatic Data Augmentation (DADA).\n",
    "    Uses RandAugment from torchvision to simulate DADA behavior.\n",
    "    \n",
    "    Args:\n",
    "        num_ops (int): Number of augmentation ops to apply.\n",
    "        magnitude (int): Magnitude for augmentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_ops=2, magnitude=9):\n",
    "        self.augment = transforms.RandAugment(num_ops=num_ops, magnitude=magnitude)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.augment(img)\n",
    "\n",
    "# Training transforms: includes augmentation and normalization\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                    # Resize input image\n",
    "    DADATransform(num_ops=2, magnitude=9),            # Apply RandAugment-style augmentation\n",
    "    transforms.RandomHorizontalFlip(),                # Random flip\n",
    "    transforms.RandomRotation(15),                    # Random rotation up to ±15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2,            # Simulate lighting variation\n",
    "                           contrast=0.2, \n",
    "                           saturation=0.2, \n",
    "                           hue=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random crop with resizing\n",
    "    transforms.ToTensor(),                            # Convert to PyTorch tensor\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),   # Normalize using ImageNet statistics\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Validation/test transforms: no augmentation, only resizing and normalization\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "print(\"Image transformations defined!\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4. DATASET CLASSES (BINARY RELABELING)\n",
    "# ---------------------------------------------\n",
    "\n",
    "class DermNetDatasetBinary(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for DermNet images with binary relabeling.\n",
    "\n",
    "    Labels:\n",
    "        - 1 if folder name indicates eczema (\"eczema photos\", \"atopic dermatitis photos\")\n",
    "        - 0 for all other folders.\n",
    "\n",
    "    Args:\n",
    "        root (str): Path to DermNet image folders.\n",
    "        transform (callable, optional): Image preprocessing transformations.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        print(f\"Initializing DermNetDatasetBinary from {root} ...\")\n",
    "        self.dataset = datasets.ImageFolder(root=root, transform=transform)\n",
    "        self.transform = transform\n",
    "\n",
    "        eczema_names = {\"eczema photos\", \"atopic dermatitis photos\"}\n",
    "        self.binary_label_map = {}\n",
    "\n",
    "        # Create binary label mapping: eczema = 1, others = 0\n",
    "        for idx, cls in enumerate(self.dataset.classes):\n",
    "            folder_name = cls.strip().lower()\n",
    "            self.binary_label_map[idx] = 1 if folder_name in eczema_names else 0\n",
    "\n",
    "        print(f\"Found {len(self.dataset)} images across {len(self.dataset.classes)} classes.\")\n",
    "        print(f\"Binary mapping: {self.binary_label_map}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        binary_label = self.binary_label_map[label]\n",
    "        dummy_fitz = torch.tensor(0, dtype=torch.long)  # Fitzpatrick not available in DermNet\n",
    "        return image, torch.tensor(binary_label, dtype=torch.long), dummy_fitz\n",
    "\n",
    "\n",
    "class PassionDatasetBinary(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for PASSION images with binary relabeling and Fitzpatrick skin types.\n",
    "\n",
    "    Labels:\n",
    "        - 1 if condition is 'eczema', else 0\n",
    "        - Fitzpatrick skin type is returned for fairness-aware training\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to CSV with subject metadata.\n",
    "        image_folder (str): Path to PASSION image directory.\n",
    "        transform (callable, optional): Image preprocessing transformations.\n",
    "        mode (str): 'train' or 'validation', used for logging/debugging.\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, image_folder, transform=None, mode=\"train\"):\n",
    "        print(f\"Initializing PassionDatasetBinary for {mode}...\")\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        # Binary label mapping: eczema = 1, other = 0\n",
    "        self.data[\"binary_label\"] = self.data[\"conditions_PASSION\"].apply(\n",
    "            lambda x: 1 if x.strip().lower() == \"eczema\" else 0\n",
    "        )\n",
    "\n",
    "        # Associate images with subject IDs\n",
    "        self.image_files = []\n",
    "        for subject_id in self.data[\"subject_id\"]:\n",
    "            subject_imgs = glob.glob(os.path.join(image_folder, f\"{subject_id}_*.jpg\"))\n",
    "            self.image_files.extend([(img, subject_id) for img in subject_imgs])\n",
    "\n",
    "        print(f\"PASSION Binary Dataset loaded: {len(self.image_files)} images for {mode}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, subject_id = self.image_files[idx]\n",
    "\n",
    "        # Retrieve metadata from CSV\n",
    "        row = self.data[self.data[\"subject_id\"] == subject_id]\n",
    "        if row.empty:\n",
    "            raise ValueError(f\"Subject {subject_id} not found in CSV.\")\n",
    "\n",
    "        label = int(row[\"binary_label\"].values[0])\n",
    "        fitz = int(row[\"fitzpatrick\"].values[0])\n",
    "\n",
    "        # Load and transform image\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long), torch.tensor(fitz, dtype=torch.long)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5. DATALOADER CREATION\n",
    "# ---------------------------------------------\n",
    "\n",
    "# --- DermNet Pretraining Dataloaders ---\n",
    "print(\"Creating DermNet dataset for pretraining (binary re-labeling)...\")\n",
    "dermnet_full = DermNetDatasetBinary(root=dermnet_train_root, transform=train_transforms)\n",
    "dermnet_len = len(dermnet_full)\n",
    "val_size = int(0.2 * dermnet_len)\n",
    "train_size = dermnet_len - val_size\n",
    "\n",
    "# Split DermNet into training and validation sets\n",
    "dermnet_train_ds, dermnet_val_ds = random_split(dermnet_full, [train_size, val_size])\n",
    "pretrain_train_loader = DataLoader(dermnet_train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "pretrain_val_loader   = DataLoader(dermnet_val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "print(f\"DermNet pretraining: {train_size} train images, {val_size} val images.\")\n",
    "\n",
    "# --- PASSION Fine-tuning Dataloaders ---\n",
    "print(\"Creating PASSION binary dataset from CSV splits...\")\n",
    "passion_train_ds = PassionDatasetBinary(train_csv, passion_image_folder, transform=train_transforms, mode=\"train\")\n",
    "passion_val_ds   = PassionDatasetBinary(val_csv, passion_image_folder, transform=valid_transforms, mode=\"validation\")\n",
    "\n",
    "train_loader = DataLoader(passion_train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(passion_val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "print(f\"PASSION binary: {len(passion_train_ds)} train images, {len(passion_val_ds)} val images.\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6. MODEL DEFINITION WITH FITZPATRICK INTEGRATION (RESNET50)\n",
    "# ---------------------------------------------\n",
    "\n",
    "class ResNet50ModelWithFitzpatrick(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom ResNet50-based model with additional Fitzpatrick skin type embedding.\n",
    "    \n",
    "    Combines visual features from a pretrained ResNet50 backbone with a learned embedding\n",
    "    of the Fitzpatrick skin type to improve fairness-aware classification.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of output classes (e.g., 2 for binary classification).\n",
    "        fitzpatrick_vocab_size (int): Number of distinct Fitzpatrick types (typically 6).\n",
    "        fitz_emb_dim (int): Dimensionality of the Fitzpatrick embedding vector.\n",
    "        dropout (float): Dropout rate for regularization.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, fitzpatrick_vocab_size, fitz_emb_dim=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        print(\"Initializing ResNet50 with Fitzpatrick embedding...\")\n",
    "\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        in_features = self.resnet.fc.in_features  # Typically 2048\n",
    "\n",
    "        self.resnet.fc = nn.Identity()  # Remove default classification layer\n",
    "\n",
    "        # Add embedding layer for Fitzpatrick skin types\n",
    "        self.fitz_emb = nn.Embedding(fitzpatrick_vocab_size, fitz_emb_dim)\n",
    "\n",
    "        # Combined classifier: visual features + Fitzpatrick embedding\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features + fitz_emb_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        print(\"ResNet50 model created!\")\n",
    "\n",
    "    def forward(self, x, fitz):\n",
    "        features = self.resnet(x)           # Extract features from images\n",
    "        emb = self.fitz_emb(fitz)           # Embed Fitzpatrick skin type\n",
    "        combined = torch.cat((features, emb), dim=1)  # Concatenate features\n",
    "        return self.classifier(combined)\n",
    "\n",
    "\n",
    "def replace_classifier_resnet(model, num_classes_new, dropout, fitz_emb_dim=32):\n",
    "    \"\"\"\n",
    "    Utility function to replace the classifier head of a ResNet50 model\n",
    "    with a new classifier supporting Fitzpatrick embeddings.\n",
    "\n",
    "    Args:\n",
    "        model (ResNet50ModelWithFitzpatrick): The base model.\n",
    "        num_classes_new (int): New number of output classes.\n",
    "        dropout (float): Dropout rate to apply.\n",
    "        fitz_emb_dim (int): Dimensionality of Fitzpatrick embedding.\n",
    "    \"\"\"\n",
    "    in_features = model.resnet.fc.in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features + fitz_emb_dim, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(256, num_classes_new)\n",
    "    )\n",
    "    print(f\"Classifier replaced with {num_classes_new} output classes.\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 7. TRAINING FUNCTION WITH EARLY STOPPING & FAIRNESS PENALTY\n",
    "# ---------------------------------------------\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, \n",
    "                num_epochs, freeze_epochs=0, fairness_lambda=0.0, patience=2, lr=1e-5):\n",
    "    \"\"\"\n",
    "    Train a model with optional layer freezing, early stopping, and fairness-aware regularization.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The ResNet model to train.\n",
    "        train_loader (DataLoader): Dataloader for training.\n",
    "        val_loader (DataLoader): Dataloader for validation.\n",
    "        device (torch.device): Device to use (CPU or GPU).\n",
    "        num_epochs (int): Total number of training epochs.\n",
    "        freeze_epochs (int): Number of initial epochs with frozen backbone.\n",
    "        fairness_lambda (float): Weight for fairness penalty between Fitzpatrick groups.\n",
    "        patience (int): Early stopping patience.\n",
    "        lr (float): Learning rate.\n",
    "    \"\"\"\n",
    "    print(f\"Starting training: freeze_epochs={freeze_epochs}, fairness_lambda={fairness_lambda}\")\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Optionally freeze ResNet backbone for initial training epochs\n",
    "    if freeze_epochs > 0:\n",
    "        for param in model.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        # --- Training loop ---\n",
    "        for batch_idx, (images, labels, fitz) in enumerate(train_loader):\n",
    "            images, labels, fitz = images.to(device), labels.to(device), fitz.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, fitz)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Fairness-aware regularization: balance loss across skin tones\n",
    "            light_mask = (fitz <= 3)\n",
    "            dark_mask = (fitz > 3)\n",
    "            if fairness_lambda > 0 and light_mask.sum() > 0 and dark_mask.sum() > 0:\n",
    "                loss_light = criterion(outputs[light_mask], labels[light_mask])\n",
    "                loss_dark = criterion(outputs[dark_mask], labels[dark_mask])\n",
    "                loss += fairness_lambda * torch.abs(loss_light - loss_dark)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Batch {batch_idx+1}/{len(train_loader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        scheduler.step()\n",
    "\n",
    "        # --- Unfreeze ResNet after freeze_epochs ---\n",
    "        if epoch == freeze_epochs:\n",
    "            print(\"Unfreezing ResNet backbone for full fine-tuning.\")\n",
    "            for param in model.resnet.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=(num_epochs - freeze_epochs))\n",
    "\n",
    "        # --- Validation loop ---\n",
    "        model.eval()\n",
    "        val_loss_sum, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels, fitz in val_loader:\n",
    "                images, labels, fitz = images.to(device), labels.to(device), fitz.to(device)\n",
    "                outputs = model(images, fitz)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss_sum += loss.item()\n",
    "                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f} | Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "        # --- Early stopping check ---\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_fold_5_{timestamp}.pth\")\n",
    "            print(\"Model improved; saved best model.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 8. FUNCTION TO APPLY PRUNING & QUANTIZATION\n",
    "# ---------------------------------------------\n",
    "\n",
    "def apply_pruning(model, amount=0.3):\n",
    "    \"\"\"\n",
    "    Applies global unstructured L1 pruning to all linear layers in the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to prune.\n",
    "        amount (float): Fraction of weights to prune (e.g., 0.3 = 30% sparsity).\n",
    "    \"\"\"\n",
    "    print(\"Applying global unstructured pruning to model...\")\n",
    "    parameters_to_prune = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "\n",
    "    prune.global_unstructured(parameters_to_prune,\n",
    "                              pruning_method=prune.L1Unstructured,\n",
    "                              amount=amount)\n",
    "    print(\"Pruning applied.\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 9. STAGE 1: PRETRAINING ON DERMNET (BINARY CLASSIFICATION)\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(\"=== Stage 1: Pretraining on DermNet (binary re-labeling) ===\")\n",
    "\n",
    "# Binary task: 0 = non-eczema, 1 = eczema\n",
    "num_dermnet_classes = 2\n",
    "\n",
    "# Use dummy Fitzpatrick embedding (vocab size = 1, since no real Fitz data)\n",
    "model = ResNet50ModelWithFitzpatrick(\n",
    "    num_classes=num_dermnet_classes,\n",
    "    fitzpatrick_vocab_size=1,\n",
    "    fitz_emb_dim=32,\n",
    "    dropout=dropout_rate\n",
    ").to(device)\n",
    "\n",
    "print(f\"Pretraining using {num_dermnet_classes} classes from DermNet...\")\n",
    "\n",
    "# Train on DermNet (no fairness penalty since Fitzpatrick data is dummy)\n",
    "train_model(\n",
    "    model,\n",
    "    pretrain_train_loader,\n",
    "    pretrain_val_loader,\n",
    "    device,\n",
    "    num_epochs=num_epochs_pretrain,\n",
    "    freeze_epochs=0,\n",
    "    fairness_lambda=0.0,\n",
    "    patience=patience_pretrain,\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "print(\"Pretraining complete on DermNet!\")\n",
    "torch.save(model.state_dict(), f\"dermnet_pretrained_model_{timestamp}.pth\")\n",
    "print(f\"DermNet pretrained model saved to dermnet_pretrained_model_{timestamp}.pth\")\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 10. STAGE 2: FINE-TUNING ON PASSION (WITH FAIRNESS REGULARIZATION)\n",
    "# ---------------------------------------------\n",
    "\n",
    "def replace_classifier(model, num_classes_new, dropout, fitz_emb_dim=32):\n",
    "    \"\"\"\n",
    "    Replace the model’s classification head for transfer learning.\n",
    "\n",
    "    Args:\n",
    "        model (ResNet50ModelWithFitzpatrick): The model to modify.\n",
    "        num_classes_new (int): New number of output classes.\n",
    "        dropout (float): Dropout rate.\n",
    "        fitz_emb_dim (int): Fitzpatrick embedding dimension.\n",
    "    \"\"\"\n",
    "    in_features = model.resnet.fc.in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features + fitz_emb_dim, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(256, num_classes_new)\n",
    "    )\n",
    "    print(f\"Classifier replaced with {num_classes_new} output classes.\")\n",
    "\n",
    "\n",
    "print(\"=== Stage 2: Fine-tuning on PASSION (binary, with fairness) ===\")\n",
    "num_passion_classes = 2  # Binary: eczema vs non-eczema\n",
    "\n",
    "# Create new model for PASSION with Fitzpatrick support (7 skin types)\n",
    "model = ResNet50ModelWithFitzpatrick(\n",
    "    num_classes=num_passion_classes,\n",
    "    fitzpatrick_vocab_size=7,\n",
    "    fitz_emb_dim=32,\n",
    "    dropout=dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# Load pretrained weights from Stage 1 (DermNet), ignoring mismatches\n",
    "print(\"Loading pretrained weights from DermNet...\")\n",
    "pretrained_weights = torch.load(f\"dermnet_pretrained_model_{timestamp}.pth\", map_location=device)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Only load weights that match in shape\n",
    "filtered_dict = {\n",
    "    k: v for k, v in pretrained_weights.items()\n",
    "    if k in model_dict and v.shape == model_dict[k].shape\n",
    "}\n",
    "model_dict.update(filtered_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "print(\"Pretrained weights loaded (excluding mismatches).\")\n",
    "\n",
    "# Replace classifier for PASSION binary classification\n",
    "replace_classifier(model, num_passion_classes, dropout_rate)\n",
    "model = model.to(device)\n",
    "\n",
    "# Fine-tune model with fairness-aware training on PASSION\n",
    "train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    num_epochs=num_epochs_finetune,\n",
    "    freeze_epochs=freeze_epochs_passion,\n",
    "    fairness_lambda=fairness_lambda_passion,\n",
    "    patience=patience_finetune,\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning complete on PASSION!\")\n",
    "torch.save(model.state_dict(), f\"best_model_fold_5_{timestamp}.pth\")\n",
    "print(f\"Fine-tuned PASSION model saved to best_model_fold_5_{timestamp}.pth\")\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 11. APPLY PRUNING & DYNAMIC QUANTIZATION AFTER FINE-TUNING\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(\"Applying pruning and dynamic quantization...\")\n",
    "\n",
    "# Apply unstructured pruning to linear layers (30% of weights)\n",
    "apply_pruning(model, amount=0.3)\n",
    "\n",
    "# Quantize linear layers dynamically to 8-bit precision for efficiency\n",
    "# This reduces model size and can improve inference speed\n",
    "model_quantized = quantize_dynamic(\n",
    "    model, {nn.Linear}, dtype=torch.qint8, inplace=True\n",
    ")\n",
    "\n",
    "# Save the quantized model\n",
    "torch.save(model_quantized.state_dict(), f\"resnet_quantized_model_{timestamp}.pth\")\n",
    "print(f\"Quantized pruned model saved to resnet_quantized_model_{timestamp}.pth\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 12. OPTUNA HYPERPARAMETER OPTIMIZATION (PASSION VALIDATION SET)\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Load best PASSION-trained model checkpoint\n",
    "model5_path = f\"best_model_fold_5_{timestamp}.pth\"\n",
    "\n",
    "# --- Helper: Train for one epoch (used during Optuna search) ---\n",
    "def train_one_epoch_optuna(model, loader, criterion, optimizer, device, fairness_lambda):\n",
    "    model.train()\n",
    "    for images, labels, fitz in loader:\n",
    "        images, labels, fitz = images.to(device), labels.to(device), fitz.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, fitz)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Apply fairness regularization if both groups exist\n",
    "        light_mask = (fitz <= 3)\n",
    "        dark_mask = (fitz > 3)\n",
    "        if fairness_lambda > 0 and light_mask.sum() > 0 and dark_mask.sum() > 0:\n",
    "            loss_light = criterion(outputs[light_mask], labels[light_mask])\n",
    "            loss_dark = criterion(outputs[dark_mask], labels[dark_mask])\n",
    "            loss += fairness_lambda * torch.abs(loss_light - loss_dark)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# --- Helper: Evaluate accuracy on validation set ---\n",
    "def evaluate_optuna(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, fitz in loader:\n",
    "            images, labels, fitz = images.to(device), labels.to(device), fitz.to(device)\n",
    "            outputs = model(images, fitz)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return accuracy_score(all_labels, all_preds)\n",
    "\n",
    "trial_log = []  # For tracking trial results\n",
    "\n",
    "# --- Optuna Objective Function ---\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters from defined search spaces\n",
    "    lr_trial = trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True)\n",
    "    weight_decay_trial = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    dropout_trial = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    fairness_lambda_trial = trial.suggest_float(\"fairness_lambda\", 0.0, 1.0)\n",
    "\n",
    "    # Initialize and load model weights\n",
    "    model_opt = ResNet50ModelWithFitzpatrick(\n",
    "        num_classes=num_passion_classes,\n",
    "        dropout=dropout_trial,\n",
    "        fitzpatrick_vocab_size=7\n",
    "    ).to(device)\n",
    "    model_opt.load_state_dict(torch.load(model5_path, map_location=device))\n",
    "\n",
    "    optimizer = optim.AdamW(model_opt.parameters(), lr=lr_trial, weight_decay=weight_decay_trial)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=5)\n",
    "\n",
    "    # Train for 5 short epochs to evaluate performance\n",
    "    for _ in range(5):\n",
    "        train_one_epoch_optuna(model_opt, valid_loader, criterion, optimizer, device, fairness_lambda_trial)\n",
    "        scheduler.step()\n",
    "\n",
    "    acc = evaluate_optuna(model_opt, valid_loader)\n",
    "\n",
    "    # Log trial details\n",
    "    trial_log.append({\n",
    "        \"trial\": trial.number,\n",
    "        \"lr\": lr_trial,\n",
    "        \"weight_decay\": weight_decay_trial,\n",
    "        \"dropout\": dropout_trial,\n",
    "        \"fairness_lambda\": fairness_lambda_trial,\n",
    "        \"accuracy\": acc\n",
    "    })\n",
    "\n",
    "    # Free up GPU memory\n",
    "    del model_opt\n",
    "    torch.cuda.empty_cache()\n",
    "    return acc\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "for _ in tqdm(range(20), desc=\"Running Optuna Trials\"):\n",
    "    study.optimize(objective, n_trials=1)  # Sequential trials to avoid memory overload\n",
    "\n",
    "# Save Optuna results to CSV\n",
    "df_log = pd.DataFrame(trial_log)\n",
    "df_log.to_csv(\"optuna_trials.csv\", index=False)\n",
    "\n",
    "# Plot accuracy per trial\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_log[\"trial\"], df_log[\"accuracy\"], marker=\"o\")\n",
    "plt.title(\"Optuna Trials: Accuracy vs Trial Number\")\n",
    "plt.xlabel(\"Trial\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"optuna_accuracy_vs_trial.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Report best hyperparameters\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "best_params = study.best_params\n",
    "\n",
    "# --- Retrain best model with best Optuna hyperparameters ---\n",
    "model_best = ResNet50ModelWithFitzpatrick(\n",
    "    num_classes=num_passion_classes,\n",
    "    dropout=best_params[\"dropout\"],\n",
    "    fitzpatrick_vocab_size=7\n",
    ").to(device)\n",
    "\n",
    "model_best.load_state_dict(torch.load(model5_path, map_location=device))\n",
    "optimizer = optim.AdamW(model_best.parameters(), lr=best_params[\"lr\"], weight_decay=best_params[\"weight_decay\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Final fine-tuning with optimal settings\n",
    "for _ in range(10):\n",
    "    train_one_epoch_optuna(model_best, valid_loader, criterion, optimizer, device, best_params[\"fairness_lambda\"])\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model_best.state_dict(), f\"resnet_finetuned_optuna_{timestamp}.pth\")\n",
    "print(f\"Model saved to resnet_finetuned_optuna_{timestamp}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779c024-2f9d-4404-b28e-5fce55f7a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# Vision Transformer (ViT) for Fairness-Aware Eczema Diagnosis\n",
    "# Author: Domante Rabasauskaite\n",
    "# Date: 09 April 2025\n",
    "# ===================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "from torch.nn.utils import prune\n",
    "from torch.quantization import quantize_dynamic\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Timestamp for output files (models, plots)\n",
    "timestamp = \"05_05_2025\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. HYPERPARAMETERS & PATHS\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# DermNet Pretraining Hyperparameters\n",
    "lr = 1e-5\n",
    "weight_decay = 1e-2\n",
    "dropout_rate = 0.2\n",
    "num_epochs_pretrain = 5           # Number of epochs for pretraining\n",
    "patience_pretrain = 2             # Early stopping patience for pretraining\n",
    "\n",
    "# PASSION Fine-Tuning Hyperparameters\n",
    "fairness_lambda_passion = 0.1     # Fairness loss weight\n",
    "num_epochs_finetune = 15          # Epochs for fine-tuning\n",
    "patience_finetune = 3             # Early stopping patience for fine-tuning\n",
    "freeze_epochs_passion = 5         # Epochs with frozen base encoder\n",
    "\n",
    "# File paths (update to match your system)\n",
    "dermnet_train_root = r\"C:\\Users\\DermNet\\train\"\n",
    "dermnet_unseen_root = r\"C:\\Users\\DermNet\\test\"  # Optional test set\n",
    "\n",
    "passion_csv_path = r\"C:\\Users\\PASSION_MICCAI_2024\\label.csv\"\n",
    "passion_image_folder = r\"C:\\Users\\PASSION_MICCAI_2024\\images\"\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. CSV SPLITTING FOR PASSION (Stratified Group K-Fold)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(\"Loading PASSION CSV...\")\n",
    "df_full = pd.read_csv(passion_csv_path)\n",
    "df_full.columns = df_full.columns.str.strip()\n",
    "print(f\"PASSION CSV loaded: {len(df_full)} rows.\")\n",
    "\n",
    "# Ensure stratified splits that preserve subject grouping\n",
    "print(\"Splitting PASSION dataset using StratifiedGroupKFold...\")\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use the first fold for training/validation split\n",
    "for train_idx, val_idx in sgkf.split(df_full, df_full[\"conditions_PASSION\"], groups=df_full[\"subject_id\"]):\n",
    "    train_df = df_full.iloc[train_idx]\n",
    "    val_df = df_full.iloc[val_idx]\n",
    "    break\n",
    "\n",
    "# Save splits for reproducibility\n",
    "train_csv = \"train_split.csv\"\n",
    "val_csv = \"val_split.csv\"\n",
    "train_df.to_csv(train_csv, index=False)\n",
    "val_df.to_csv(val_csv, index=False)\n",
    "print(f\"PASSION split complete: {len(train_df)} train rows, {len(val_df)} val rows.\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. IMAGE TRANSFORMATIONS (DADA Proxy Augmentation)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(\"Defining image transformations...\")\n",
    "\n",
    "class DADATransform:\n",
    "    \"\"\"\n",
    "    DADA-style transformation using RandAugment as a proxy.\n",
    "\n",
    "    Args:\n",
    "        num_ops (int): Number of random ops to apply.\n",
    "        magnitude (int): Strength of the augmentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_ops=2, magnitude=9):\n",
    "        self.augment = transforms.RandAugment(num_ops=num_ops, magnitude=magnitude)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.augment(img)\n",
    "\n",
    "# Training transforms: RandAugment + common augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    DADATransform(num_ops=2, magnitude=9),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Validation/test transforms: only resizing + normalization\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "print(\"Image transformations defined!\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. DATASET CLASSES (BINARY RE-LABELING)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "class DermNetDatasetBinary(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for binary eczema classification from DermNet.\n",
    "    Converts multiclass folders to binary labels:\n",
    "        - 1 = eczema or atopic dermatitis\n",
    "        - 0 = all other conditions\n",
    "\n",
    "    Fitzpatrick score is not available, so a dummy value of 0 is returned.\n",
    "    \n",
    "    Args:\n",
    "        root (str): Path to DermNet image folders.\n",
    "        transform (callable): Transformations to apply to each image.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        print(f\"Initializing DermNetDatasetBinary from {root} ...\")\n",
    "        self.dataset = datasets.ImageFolder(root=root, transform=transform)\n",
    "        self.transform = transform\n",
    "\n",
    "        eczema_names = {\"eczema photos\", \"atopic dermatitis photos\"}\n",
    "        self.binary_label_map = {}\n",
    "\n",
    "        for idx, cls in enumerate(self.dataset.classes):\n",
    "            folder_name = cls.strip().lower()\n",
    "            self.binary_label_map[idx] = 1 if folder_name in eczema_names else 0\n",
    "\n",
    "        print(f\"Found {len(self.dataset)} images across {len(self.dataset.classes)} classes.\")\n",
    "        print(f\"Binary mapping: {self.binary_label_map}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        binary_label = self.binary_label_map[label]\n",
    "        dummy_fitz = torch.tensor(0, dtype=torch.long)  # Fitzpatrick score not present in DermNet\n",
    "        return image, torch.tensor(binary_label, dtype=torch.long), dummy_fitz\n",
    "\n",
    "\n",
    "class PassionDatasetBinary(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for binary eczema classification from PASSION.\n",
    "    Binary labels and Fitzpatrick scores are derived from the CSV.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): CSV with subject_id, condition, and Fitzpatrick info.\n",
    "        image_folder (str): Path to PASSION image files.\n",
    "        transform (callable): Transformations to apply to each image.\n",
    "        mode (str): 'train' or 'validation' (for logging/debugging).\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, image_folder, transform=None, mode=\"train\"):\n",
    "        print(f\"Initializing PassionDatasetBinary for {mode}...\")\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        # Create binary labels\n",
    "        self.data[\"binary_label\"] = self.data[\"conditions_PASSION\"].apply(\n",
    "            lambda x: 1 if x.strip().lower() == \"eczema\" else 0\n",
    "        )\n",
    "\n",
    "        # Match images to subject IDs\n",
    "        self.image_files = []\n",
    "        for subject_id in self.data[\"subject_id\"]:\n",
    "            subject_imgs = glob.glob(os.path.join(image_folder, f\"{subject_id}_*.jpg\"))\n",
    "            self.image_files.extend([(img, subject_id) for img in subject_imgs])\n",
    "\n",
    "        print(f\"PASSION Binary Dataset loaded: {len(self.image_files)} images for {mode}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, subject_id = self.image_files[idx]\n",
    "\n",
    "        row = self.data[self.data[\"subject_id\"] == subject_id]\n",
    "        if row.empty:\n",
    "            raise ValueError(f\"Subject {subject_id} not found in CSV.\")\n",
    "\n",
    "        label = int(row[\"binary_label\"].values[0])\n",
    "        fitz = int(row[\"fitzpatrick\"].values[0])\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long), torch.tensor(fitz, dtype=torch.long)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. CREATE DATALOADERS\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# --- DermNet Pretraining ---\n",
    "print(\"Creating DermNet dataset for pretraining (binary re-labeling)...\")\n",
    "dermnet_full = DermNetDatasetBinary(root=dermnet_train_root, transform=train_transforms)\n",
    "dermnet_len = len(dermnet_full)\n",
    "val_size = int(0.2 * dermnet_len)\n",
    "train_size = dermnet_len - val_size\n",
    "\n",
    "# Random split of DermNet\n",
    "dermnet_train_ds, dermnet_val_ds = random_split(dermnet_full, [train_size, val_size])\n",
    "\n",
    "pretrain_train_loader = DataLoader(dermnet_train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "pretrain_val_loader   = DataLoader(dermnet_val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"DermNet pretraining: {train_size} train images, {val_size} val images.\")\n",
    "\n",
    "# --- PASSION Fine-tuning ---\n",
    "print(\"Creating PASSION binary dataset from CSV splits...\")\n",
    "passion_train_ds = PassionDatasetBinary(train_csv, passion_image_folder, transform=train_transforms, mode=\"train\")\n",
    "passion_val_ds   = PassionDatasetBinary(val_csv, passion_image_folder, transform=valid_transforms, mode=\"validation\")\n",
    "\n",
    "train_loader = DataLoader(passion_train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(passion_val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"PASSION binary: {len(passion_train_ds)} train images, {len(passion_val_ds)} val images.\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. MODEL DEFINITION WITH FITZPATRICK INTEGRATION (ViT)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "class ViTModelWithFitzpatrick(nn.Module):\n",
    "    \"\"\"\n",
    "    Vision Transformer (ViT-Base/16) with Fitzpatrick skin type embedding for fairness-aware classification.\n",
    "\n",
    "    Combines image features from a pretrained ViT backbone with a learned embedding of the Fitzpatrick type.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of output classes (e.g., 2 for binary classification).\n",
    "        fitzpatrick_vocab_size (int): Number of distinct Fitzpatrick types (e.g., 7).\n",
    "        fitz_emb_dim (int): Dimensionality of Fitzpatrick embedding.\n",
    "        dropout (float): Dropout rate before final classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, fitzpatrick_vocab_size, fitz_emb_dim=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        print(\"Initializing ViT with Fitzpatrick embedding...\")\n",
    "\n",
    "        # Load pretrained ViT-Base/16 from TIMM\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        in_features = self.vit.head.in_features  # Should be 768 for ViT-Base\n",
    "\n",
    "        self.vit.head = nn.Identity()  # Remove default classifier head\n",
    "        self.fitz_emb = nn.Embedding(fitzpatrick_vocab_size, fitz_emb_dim)\n",
    "\n",
    "        # Combined classifier: [ViT features + Fitzpatrick embedding]\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features + fitz_emb_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        print(\"ViT model created!\")\n",
    "\n",
    "    def forward(self, x, fitz):\n",
    "        vit_features = self.vit(x)              # [B, 768]\n",
    "        emb = self.fitz_emb(fitz)               # [B, 32]\n",
    "        combined = torch.cat((vit_features, emb), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "\n",
    "def replace_classifier(model, num_classes_new, dropout, fitz_emb_dim=32):\n",
    "    \"\"\"\n",
    "    Utility function to replace the ViT classifier block with new output dimensions.\n",
    "\n",
    "    Args:\n",
    "        model (ViTModelWithFitzpatrick): ViT model with Fitzpatrick embedding.\n",
    "        num_classes_new (int): New number of output classes.\n",
    "        dropout (float): Dropout probability.\n",
    "        fitz_emb_dim (int): Dimensionality of Fitzpatrick embedding.\n",
    "    \"\"\"\n",
    "    in_features = 768  # ViT-Base patch16 output\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features + fitz_emb_dim, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(256, num_classes_new)\n",
    "    )\n",
    "    print(f\"Classifier replaced with {num_classes_new} output classes.\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 7. TRAINING FUNCTION WITH EARLY STOPPING & FAIRNESS PENALTY\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, \n",
    "                num_epochs, freeze_epochs=0, fairness_lambda=0.0, patience=2, lr=1e-5):\n",
    "    \"\"\"\n",
    "    Trains the ViT model with optional backbone freezing, fairness loss regularization, and early stopping.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): Training data loader.\n",
    "        val_loader (DataLoader): Validation data loader.\n",
    "        device (torch.device): Target device (CPU or GPU).\n",
    "        num_epochs (int): Total number of epochs.\n",
    "        freeze_epochs (int): Number of epochs to keep the backbone frozen.\n",
    "        fairness_lambda (float): Fairness loss weight (penalizes subgroup disparities).\n",
    "        patience (int): Early stopping patience.\n",
    "        lr (float): Learning rate.\n",
    "    \"\"\"\n",
    "    print(f\"Starting training: freeze_epochs={freeze_epochs}, fairness_lambda={fairness_lambda}\")\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Optional: Freeze ViT backbone initially\n",
    "    if freeze_epochs > 0:\n",
    "        for param in model.vit.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        # --- Training loop ---\n",
    "        for batch_idx, (images, labels, fitz) in enumerate(train_loader):\n",
    "            images, labels, fitz = images.to(device), labels.to(device), fitz.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images, fitz)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Fairness penalty: balance subgroup loss\n",
    "            light_mask = (fitz <= 3)\n",
    "            dark_mask = (fitz > 3)\n",
    "            if fairness_lambda > 0 and light_mask.sum() > 0 and dark_mask.sum() > 0:\n",
    "                loss_light = criterion(outputs[light_mask], labels[light_mask])\n",
    "                loss_dark = criterion(outputs[dark_mask], labels[dark_mask])\n",
    "                loss += fairness_lambda * torch.abs(loss_light - loss_dark)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Batch {batch_idx+1}/{len(train_loader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        scheduler.step()\n",
    "\n",
    "        # Unfreeze backbone after freeze_epochs\n",
    "        if epoch == freeze_epochs:\n",
    "            print(\"Unfreezing ViT backbone for full fine-tuning.\")\n",
    "            for param in model.vit.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=(num_epochs - freeze_epochs))\n",
    "\n",
    "        # --- Validation loop ---\n",
    "        model.eval()\n",
    "        val_loss_sum, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels, fitz in val_loader:\n",
    "                images, labels, fitz = images.to(device), labels.to(device), fitz.to(device)\n",
    "                outputs = model(images, fitz)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss_sum += loss.item()\n",
    "                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f} | Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "        # --- Early stopping ---\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_fold_5_{timestamp}.pth\")\n",
    "            print(\"Model improved; saved best model.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 8. FUNCTION TO APPLY PRUNING & DYNAMIC QUANTIZATION\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def apply_pruning(model, amount=0.3):\n",
    "    \"\"\"\n",
    "    Applies global unstructured L1 pruning to all linear layers in the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model to prune.\n",
    "        amount (float): Proportion of weights to prune (e.g., 0.3 = 30%).\n",
    "    \"\"\"\n",
    "    print(\"Applying global unstructured pruning to model...\")\n",
    "\n",
    "    parameters_to_prune = [\n",
    "        (module, 'weight')\n",
    "        for module in model.modules()\n",
    "        if isinstance(module, nn.Linear)\n",
    "    ]\n",
    "\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=amount\n",
    "    )\n",
    "\n",
    "    print(\"Pruning applied.\")\n",
    "\n",
    "    # Remove pruning hooks to convert pruned layers back to standard form\n",
    "    for module, name in parameters_to_prune:\n",
    "        try:\n",
    "            prune.remove(module, name)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not remove pruning from module {module}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 9. STAGE 1: PRETRAINING ON DERMNET (BINARY)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(\"=== Stage 1: Pretraining on DermNet (binary re-labeling) ===\")\n",
    "num_dermnet_classes = 2  # Binary classification: eczema vs non-eczema\n",
    "\n",
    "# Dummy Fitzpatrick score (vocab size = 1) for pretraining\n",
    "model = ViTModelWithFitzpatrick(\n",
    "    num_classes=num_dermnet_classes,\n",
    "    fitzpatrick_vocab_size=1,\n",
    "    fitz_emb_dim=32,\n",
    "    dropout=dropout_rate\n",
    ").to(device)\n",
    "\n",
    "print(f\"Pretraining using {num_dermnet_classes} classes from DermNet...\")\n",
    "\n",
    "# Pretrain without fairness penalty\n",
    "train_model(\n",
    "    model,\n",
    "    pretrain_train_loader,\n",
    "    pretrain_val_loader,\n",
    "    device,\n",
    "    num_epochs=num_epochs_pretrain,\n",
    "    freeze_epochs=0,\n",
    "    fairness_lambda=0.0,\n",
    "    patience=patience_pretrain,\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), f\"dermnet_pretrained_model_{timestamp}.pth\")\n",
    "print(f\"DermNet pretrained model saved to dermnet_pretrained_model_{timestamp}.pth\")\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 10. STAGE 2: FINE-TUNING ON PASSION (WITH FAIRNESS)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def replace_classifier(model, num_classes_new, dropout, fitz_emb_dim=32):\n",
    "    \"\"\"\n",
    "    Replace the ViT classifier block for fine-tuning with new output classes.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): ViT model.\n",
    "        num_classes_new (int): Output class count.\n",
    "        dropout (float): Dropout rate.\n",
    "        fitz_emb_dim (int): Fitzpatrick embedding dimension.\n",
    "    \"\"\"\n",
    "    in_features = 768  # ViT Base Patch16 output size\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features + fitz_emb_dim, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(256, num_classes_new)\n",
    "    )\n",
    "    print(f\"Classifier replaced with {num_classes_new} output classes.\")\n",
    "\n",
    "print(\"=== Stage 2: Fine-tuning on PASSION (binary, with fairness) ===\")\n",
    "num_passion_classes = 2  # Still binary (eczema vs non-eczema)\n",
    "\n",
    "# Create new model with Fitzpatrick integration (7 skin types)\n",
    "model = ViTModelWithFitzpatrick(\n",
    "    num_classes=num_passion_classes,\n",
    "    fitzpatrick_vocab_size=7,\n",
    "    fitz_emb_dim=32,\n",
    "    dropout=dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# Load pretrained weights from DermNet\n",
    "print(\"Loading pretrained weights from DermNet...\")\n",
    "pretrained_weights = torch.load(f\"dermnet_pretrained_model_{timestamp}.pth\", map_location=device)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Match only compatible layers\n",
    "filtered_dict = {\n",
    "    k: v for k, v in pretrained_weights.items()\n",
    "    if k in model_dict and v.shape == model_dict[k].shape\n",
    "}\n",
    "model_dict.update(filtered_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "print(\"Pretrained weights loaded (excluding mismatches).\")\n",
    "\n",
    "# Replace classifier for PASSION binary classification\n",
    "replace_classifier(model, num_passion_classes, dropout_rate)\n",
    "model = model.to(device)\n",
    "\n",
    "# Train with fairness-aware penalty on PASSION\n",
    "train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    num_epochs=num_epochs_finetune,\n",
    "    freeze_epochs=freeze_epochs_passion,\n",
    "    fairness_lambda=fairness_lambda_passion,\n",
    "    patience=patience_finetune,\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), f\"best_model_fold_5_{timestamp}.pth\")\n",
    "print(f\"Fine-tuned PASSION model saved to best_model_fold_5_{timestamp}.pth\")\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 11. APPLY PRUNING & DYNAMIC QUANTIZATION AFTER FINE-TUNING\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(\"Applying pruning and dynamic quantization...\")\n",
    "\n",
    "# Apply global unstructured L1 pruning to all linear layers\n",
    "apply_pruning(model, amount=0.3)\n",
    "\n",
    "# Quantize linear layers to int8 precision (dynamic quantization)\n",
    "model_quantized = quantize_dynamic(\n",
    "    model, {nn.Linear}, dtype=torch.qint8, inplace=True\n",
    ")\n",
    "\n",
    "# Save compressed model\n",
    "torch.save(model_quantized.state_dict(), f\"vit_quantized_model_{timestamp}.pth\")\n",
    "print(f\"Quantized pruned model saved to vit_quantized_model_{timestamp}.pth\")\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 12. OPTUNA HYPERPARAMETER OPTIMIZATION (PASSION VALIDATION SET)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "model5_path = f\"best_model_fold_5_{timestamp}.pth\"  # Checkpoint used as starting point\n",
    "\n",
    "# --- Helper: One Epoch of Fairness-Aware Training ---\n",
    "def train_one_epoch_optuna(model, loader, criterion, optimizer, device, fairness_lambda):\n",
    "    model.train()\n",
    "    for images, labels, fitz in loader:\n",
    "        images, labels, fitz = images.to(device), labels.to(device), fitz.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, fitz)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Fairness penalty between light and dark Fitzpatrick groups\n",
    "        light_mask = (fitz <= 3)\n",
    "        dark_mask = (fitz > 3)\n",
    "        if fairness_lambda > 0 and light_mask.sum() > 0 and dark_mask.sum() > 0:\n",
    "            loss_light = criterion(outputs[light_mask], labels[light_mask])\n",
    "            loss_dark = criterion(outputs[dark_mask], labels[dark_mask])\n",
    "            loss += fairness_lambda * torch.abs(loss_light - loss_dark)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# --- Helper: Evaluation Metric (Accuracy) ---\n",
    "def evaluate_optuna(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, fitz in loader:\n",
    "            images, labels, fitz = images.to(device), labels.to(device), fitz.to(device)\n",
    "            outputs = model(images, fitz)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# --- Optuna Objective Function ---\n",
    "trial_log = []\n",
    "\n",
    "def objective(trial):\n",
    "    lr_trial = trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True)\n",
    "    weight_decay_trial = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    dropout_trial = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    fairness_lambda_trial = trial.suggest_float(\"fairness_lambda\", 0.0, 1.0)\n",
    "\n",
    "    model_opt = ViTModelWithFitzpatrick(\n",
    "        num_classes=num_passion_classes,\n",
    "        dropout=dropout_trial,\n",
    "        fitzpatrick_vocab_size=7\n",
    "    ).to(device)\n",
    "    model_opt.load_state_dict(torch.load(model5_path, map_location=device))\n",
    "\n",
    "    optimizer = optim.AdamW(model_opt.parameters(), lr=lr_trial, weight_decay=weight_decay_trial)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=5)\n",
    "\n",
    "    for _ in range(5):\n",
    "        train_one_epoch_optuna(model_opt, valid_loader, criterion, optimizer, device, fairness_lambda_trial)\n",
    "        scheduler.step()\n",
    "\n",
    "    acc = evaluate_optuna(model_opt, valid_loader)\n",
    "\n",
    "    trial_log.append({\n",
    "        \"trial\": trial.number,\n",
    "        \"lr\": lr_trial,\n",
    "        \"weight_decay\": weight_decay_trial,\n",
    "        \"dropout\": dropout_trial,\n",
    "        \"fairness_lambda\": fairness_lambda_trial,\n",
    "        \"accuracy\": acc\n",
    "    })\n",
    "\n",
    "    del model_opt\n",
    "    torch.cuda.empty_cache()\n",
    "    return acc\n",
    "\n",
    "# --- Run Optuna Tuning Loop ---\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "for _ in tqdm(range(20), desc=\"Running Optuna Trials\"):\n",
    "    study.optimize(objective, n_trials=1)\n",
    "\n",
    "# Save tuning results\n",
    "df_log = pd.DataFrame(trial_log)\n",
    "df_log.to_csv(\"optuna_trials.csv\", index=False)\n",
    "\n",
    "# Plot tuning curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_log[\"trial\"], df_log[\"accuracy\"], marker=\"o\")\n",
    "plt.title(\"Optuna Trials: Accuracy vs Trial Number\")\n",
    "plt.xlabel(\"Trial\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"optuna_accuracy_vs_trial.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Best Trial Results ---\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "best_params = study.best_params\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Retrain Best Model Using Optimal Hyperparameters\n",
    "# ---------------------------------------------------\n",
    "\n",
    "model_best = ViTModelWithFitzpatrick(\n",
    "    num_classes=num_passion_classes,\n",
    "    dropout=best_params[\"dropout\"],\n",
    "    fitzpatrick_vocab_size=7\n",
    ").to(device)\n",
    "model_best.load_state_dict(torch.load(model5_path, map_location=device))\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model_best.parameters(),\n",
    "    lr=best_params[\"lr\"],\n",
    "    weight_decay=best_params[\"weight_decay\"]\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Final training on validation set using best trial\n",
    "for _ in range(10):\n",
    "    train_one_epoch_optuna(model_best, valid_loader, criterion, optimizer, device, best_params[\"fairness_lambda\"])\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model_best.state_dict(), f\"vit_finetuned_optuna_{timestamp}.pth\")\n",
    "print(f\"Model saved to vit_finetuned_optuna_{timestamp}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ee196-0e5a-46a1-acee-91c0631ce949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
