{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5645b-348d-4856-9250-d63ef348ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Compares fine-tuned ViT and ResNet models for binary eczema classification on the PASSION MICCAI 2024 dataset.\n",
    "Evaluates classification metrics and fairness across Fitzpatrick skin types.\n",
    "\n",
    "Author: Domante Rabasauskaite\n",
    "Date: 13_04_2025\n",
    "\"\"\"\n",
    "\n",
    "# ================================\n",
    "# 1. IMPORTS AND CONFIGURATION\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, classification_report,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Optional imports for scheduling, pruning, quantization, hyperparameter tuning\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from torch.nn.utils import prune\n",
    "from torch.quantization import quantize_dynamic\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set timestamp for file naming\n",
    "timestamp = \"13_04_2025\"\n",
    "\n",
    "# Evaluation hyperparameters (if needed for advanced setups)\n",
    "lr = 1e-5\n",
    "weight_decay = 1e-2\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# Path to PASSION MICCAI dataset\n",
    "csv_path = r\"C:\\Users\\PASSION_MICCAI_2024\\label.csv\"\n",
    "image_folder = r\"C:\\Users\\PASSION_MICCAI_2024\\images\"\n",
    "\n",
    "# Select GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ================================\n",
    "# 2. PASSION DATASET LOADER\n",
    "# ================================\n",
    "\n",
    "class PassionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch dataset for PASSION MICCAI 2024.\n",
    "    \n",
    "    Each sample contains:\n",
    "        - A resized image\n",
    "        - A binary label (1 if eczema, else 0)\n",
    "        - A Fitzpatrick skin type label\n",
    "\n",
    "    Parameters:\n",
    "        csv_file (str): Path to the PASSION label CSV file.\n",
    "        image_folder (str): Path to the folder containing subject images.\n",
    "        target_condition (str): The condition to classify (default: 'eczema').\n",
    "        transform (callable): Image preprocessing pipeline.\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, image_folder, target_condition=\"eczema\", transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data.columns = self.data.columns.str.strip()  # Remove trailing spaces in column headers\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        # Generate binary label: 1 if condition is eczema, else 0\n",
    "        self.data[\"label\"] = (self.data[\"conditions_PASSION\"].str.lower() == target_condition.lower()).astype(int)\n",
    "        self.label_map = {0: f\"Not {target_condition}\", 1: target_condition}\n",
    "\n",
    "        # Match subject IDs to images\n",
    "        self.image_files = []\n",
    "        for subject_id in self.data[\"subject_id\"]:\n",
    "            subject_imgs = glob.glob(os.path.join(image_folder, f\"{subject_id}_*.jpg\"))\n",
    "            self.image_files.extend([(img, subject_id) for img in subject_imgs])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, subject_id = self.image_files[idx]\n",
    "        row = self.data[self.data[\"subject_id\"] == subject_id]\n",
    "        label = row[\"label\"].values[0]\n",
    "        fitz = row[\"fitzpatrick\"].values[0]\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long), torch.tensor(fitz, dtype=torch.long)\n",
    "\n",
    "# ================================\n",
    "# 3. IMAGE TRANSFORMATIONS\n",
    "# ================================\n",
    "\n",
    "# Standard preprocessing for evaluation\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    )\n",
    "])\n",
    "# ================================\n",
    "# 4. MODEL DEFINITIONS\n",
    "# ================================\n",
    "\n",
    "# ---- Vision Transformer (ViT) with Fitzpatrick Embedding ----\n",
    "\n",
    "class ViTModelWithFitzpatrick(nn.Module):\n",
    "    \"\"\"\n",
    "    Vision Transformer model with Fitzpatrick skin type integration.\n",
    "    \n",
    "    The Fitzpatrick value is passed through an embedding layer, then concatenated\n",
    "    with the ViT backbone output before final classification.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of output classes (e.g. 2 for binary classification).\n",
    "        fitzpatrick_vocab_size (int): Number of unique Fitzpatrick values (e.g. 7).\n",
    "        fitz_emb_dim (int): Size of embedding vector for Fitzpatrick types.\n",
    "        dropout (float): Dropout rate for classifier head.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, fitzpatrick_vocab_size, fitz_emb_dim=32, dropout=0.2):\n",
    "        super(ViTModelWithFitzpatrick, self).__init__()\n",
    "        print(\"Initializing ViT-based model with Fitzpatrick embedding...\")\n",
    "\n",
    "        # Load pretrained Vision Transformer (ViT-Base, 16x16 patch size)\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        in_features = self.vit.head.in_features  # Output size from ViT: typically 768\n",
    "        self.vit.head = nn.Identity()  # Remove final classification head\n",
    "\n",
    "        # Add Fitzpatrick embedding\n",
    "        self.fitz_emb = nn.Embedding(fitzpatrick_vocab_size, fitz_emb_dim)\n",
    "\n",
    "        # Final classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features + fitz_emb_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "        print(\"ViT model created.\")\n",
    "\n",
    "    def forward(self, x, fitz):\n",
    "        vit_features = self.vit(x)              # Extract features from ViT\n",
    "        emb = self.fitz_emb(fitz)               # Embed Fitzpatrick score\n",
    "        combined = torch.cat((vit_features, emb), dim=1)  # Concatenate features\n",
    "        return self.classifier(combined)\n",
    "\n",
    "\n",
    "# ---- ResNet50 with Fitzpatrick Embedding ----\n",
    "\n",
    "class ResNet50ModelWithFitzpatrick(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet50 model with Fitzpatrick skin type integration.\n",
    "    \n",
    "    The Fitzpatrick value is passed through an embedding layer, then concatenated\n",
    "    with the ResNet backbone output before final classification.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of output classes.\n",
    "        fitzpatrick_vocab_size (int): Size of vocabulary for Fitzpatrick types.\n",
    "        fitz_emb_dim (int): Embedding size.\n",
    "        dropout (float): Dropout rate used in the classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, fitzpatrick_vocab_size, fitz_emb_dim=32, dropout=0.2):\n",
    "        super(ResNet50ModelWithFitzpatrick, self).__init__()\n",
    "        print(\"Initializing ResNet50-based model with Fitzpatrick embedding...\")\n",
    "\n",
    "        # Load pretrained ResNet50 and remove its final classifier\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        in_features = self.resnet.fc.in_features  # Output size from ResNet: typically 2048\n",
    "        self.resnet.fc = nn.Identity()  # Remove classification head\n",
    "\n",
    "        # Add Fitzpatrick embedding\n",
    "        self.fitz_emb = nn.Embedding(fitzpatrick_vocab_size, fitz_emb_dim)\n",
    "\n",
    "        # New classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features + fitz_emb_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "        print(\"ResNet50 model created.\")\n",
    "\n",
    "    def forward(self, x, fitz):\n",
    "        features = self.resnet(x)               # Extract features from ResNet\n",
    "        emb = self.fitz_emb(fitz)               # Embed Fitzpatrick score\n",
    "        combined = torch.cat((features, emb), dim=1)  # Concatenate features\n",
    "        return self.classifier(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e279a91-1f24-4bf5-a537-d29856e5148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. EVALUATION FUNCTION\n",
    "# ================================\n",
    "\n",
    "def evaluate_model(model_class, model_path, dataloader, num_classes, device, fitzpatrick_vocab_size):\n",
    "    \"\"\"\n",
    "    Loads a saved model checkpoint and evaluates it on a test dataloader.\n",
    "\n",
    "    Args:\n",
    "        model_class (nn.Module): The model architecture class to instantiate (e.g. ViTModelWithFitzpatrick).\n",
    "        model_path (str): Path to the model weights (.pth file).\n",
    "        dataloader (DataLoader): PyTorch dataloader for test set.\n",
    "        num_classes (int): Number of output classes (e.g. 2 for binary).\n",
    "        device (torch.device): CUDA or CPU.\n",
    "        fitzpatrick_vocab_size (int): Vocabulary size of Fitzpatrick embeddings.\n",
    "\n",
    "    Returns:\n",
    "        - acc (float): Overall accuracy.\n",
    "        - cm (ndarray): Confusion matrix.\n",
    "        - prec (float): Precision score.\n",
    "        - rec (float): Recall score.\n",
    "        - f1 (float): F1 score.\n",
    "        - spec (float): Specificity (recall for class 0).\n",
    "        - report (dict): Classification report (as dictionary).\n",
    "        - fitz_acc (dict): Dictionary of accuracy per Fitzpatrick skin type.\n",
    "    \"\"\"\n",
    "    # Instantiate model and load weights\n",
    "    model = model_class(num_classes=num_classes, fitzpatrick_vocab_size=fitzpatrick_vocab_size)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model_state = model.state_dict()\n",
    "\n",
    "    # Handle potential classifier shape mismatches\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"classifier.3\") and key in model_state:\n",
    "            if state_dict[key].shape != model_state[key].shape:\n",
    "                print(f\"Skipping loading {key} due to shape mismatch.\")\n",
    "                state_dict.pop(key)\n",
    "\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Store all predictions and ground truths\n",
    "    all_preds, all_labels, all_fitz = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, fitz in dataloader:\n",
    "            images, fitz = images.to(device), fitz.to(device)\n",
    "            outputs = model(images, fitz)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_fitz.extend(fitz.cpu().numpy())\n",
    "\n",
    "    # Classification metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    spec = recall_score(all_labels, all_preds, pos_label=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "    # Fitzpatrick group-wise accuracy (fairness check)\n",
    "    fitz_groups = {}\n",
    "    for pred, true, fitz in zip(all_preds, all_labels, all_fitz):\n",
    "        if fitz not in fitz_groups:\n",
    "            fitz_groups[fitz] = {'correct': 0, 'total': 0}\n",
    "        fitz_groups[fitz]['correct'] += int(pred == true)\n",
    "        fitz_groups[fitz]['total'] += 1\n",
    "\n",
    "    fitz_acc = {\n",
    "        f\"Fitzpatrick {k}\": v['correct'] / v['total'] if v['total'] > 0 else 0.0\n",
    "        for k, v in fitz_groups.items()\n",
    "    }\n",
    "\n",
    "    return acc, cm, prec, rec, f1, spec, report, fitz_acc\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6. MAIN COMPARISON SCRIPT\n",
    "# ================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Runs the evaluation pipeline:\n",
    "    - Loads test data from the PASSION dataset.\n",
    "    - Evaluates both ViT and ResNet models on classification metrics.\n",
    "    - Computes and displays fairness-aware accuracy (Fitzpatrick group).\n",
    "    - Visualizes results with bar chart and confusion matrices.\n",
    "    \"\"\"\n",
    "    \n",
    "    # === Load PASSION test dataset ===\n",
    "    dataset = PassionDataset(\n",
    "        csv_file=csv_path,\n",
    "        image_folder=image_folder,\n",
    "        target_condition=\"eczema\",\n",
    "        transform=test_transforms\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Classification settings\n",
    "    num_classes = 2\n",
    "    fitzpatrick_vocab_size = 7\n",
    "\n",
    "    # Checkpoints to evaluate (can add more models here)\n",
    "    vit_model_files = [f\"vit_finetuned_optuna_09_04_2025.pth\"]\n",
    "    resnet_model_files = [f\"resnet_finetuned_optuna_09_04_2025.pth\"]\n",
    "    vit_labels = [\"ViT Finetuned Optuna\"]\n",
    "    resnet_labels = [\"ResNet Finetuned Optuna\"]\n",
    "\n",
    "    # Storage for all evaluation metrics\n",
    "    model_names, accuracies, conf_matrices = [], [], []\n",
    "    precisions, recalls, f1s, specificities = [], [], [], []\n",
    "    fitz_metrics_all = []\n",
    "\n",
    "    # === Evaluate ViT Models ===\n",
    "    for model_file, label in zip(vit_model_files, vit_labels):\n",
    "        print(f\"Evaluating ViT model: {model_file} ...\")\n",
    "        acc, cm, prec, rec, f1, spec, report, fitz_acc = evaluate_model(\n",
    "            ViTModelWithFitzpatrick, model_file, dataloader,\n",
    "            num_classes, device, fitzpatrick_vocab_size\n",
    "        )\n",
    "        model_names.append(label)\n",
    "        accuracies.append(acc)\n",
    "        conf_matrices.append(cm)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "        specificities.append(spec)\n",
    "        fitz_metrics_all.append(fitz_acc)\n",
    "\n",
    "        print(f\"{label} Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, \"\n",
    "              f\"F1: {f1:.4f}, Specificity: {spec:.4f}\")\n",
    "\n",
    "    # === Evaluate ResNet Models ===\n",
    "    for model_file, label in zip(resnet_model_files, resnet_labels):\n",
    "        print(f\"Evaluating ResNet model: {model_file} ...\")\n",
    "        acc, cm, prec, rec, f1, spec, report, fitz_acc = evaluate_model(\n",
    "            ResNet50ModelWithFitzpatrick, model_file, dataloader,\n",
    "            num_classes, device, fitzpatrick_vocab_size\n",
    "        )\n",
    "        model_names.append(label)\n",
    "        accuracies.append(acc)\n",
    "        conf_matrices.append(cm)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "        specificities.append(spec)\n",
    "        fitz_metrics_all.append(fitz_acc)\n",
    "\n",
    "        print(f\"{label} Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, \"\n",
    "              f\"F1: {f1:.4f}, Specificity: {spec:.4f}\")\n",
    "\n",
    "    # === Fairness Metrics: Fitzpatrick Skin Type Accuracy ===\n",
    "    print(\"\\n--- Fitzpatrick Group Accuracy (Fairness Check) ---\")\n",
    "    for name, fitz_acc in zip(model_names, fitz_metrics_all):\n",
    "        print(f\"\\n{name}:\")\n",
    "        for group, acc in fitz_acc.items():\n",
    "            print(f\"  {group}: {acc:.4f}\")\n",
    "\n",
    "    # === Plot Accuracy Bar Chart ===\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bars = plt.bar(model_names, accuracies, color=[\"skyblue\", \"seagreen\"])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Eczema Classification Accuracy Comparison (ViT vs. ResNet)\")\n",
    "\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, acc + 0.02, f\"{acc:.4f}\",\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"eczema_comparison_accuracy.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # === Plot Side-by-Side Confusion Matrices ===\n",
    "    fig, axes = plt.subplots(1, len(conf_matrices), figsize=(6 * len(conf_matrices), 6))\n",
    "\n",
    "    if len(conf_matrices) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (ax, cm) in enumerate(zip(axes, conf_matrices)):\n",
    "        sns.heatmap(\n",
    "            cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=list(dataset.label_map.values()),\n",
    "            yticklabels=list(dataset.label_map.values()),\n",
    "            ax=ax, cbar=False\n",
    "        )\n",
    "        ax.set_title(f\"Confusion Matrix - {model_names[i]}\", fontsize=13)\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"True\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"eczema_comparison_conf_matrices.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Entrypoint for script execution\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b7e2a-9b3f-4a2f-a481-061ff6b81cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# 5. EVALUATION FUNCTION\n",
    "###############################################\n",
    "\n",
    "def evaluate_model(model_class, model_path, dataloader, num_classes, device, fitzpatrick_vocab_size):\n",
    "    \"\"\"\n",
    "    Evaluates a given model on a dataloader and computes:\n",
    "      - accuracy, precision, recall, F1 score, specificity\n",
    "      - confusion matrix\n",
    "      - full classification report\n",
    "      - group-wise Fitzpatrick accuracy (for fairness analysis)\n",
    "    \"\"\"\n",
    "    model = model_class(num_classes=num_classes, fitzpatrick_vocab_size=fitzpatrick_vocab_size)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model_state = model.state_dict()\n",
    "\n",
    "    # Handle shape mismatches (e.g., classifier layers) by skipping incompatible keys\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"classifier.3\") and key in model_state:\n",
    "            if state_dict[key].shape != model_state[key].shape:\n",
    "                print(f\"Skipping loading {key} due to shape mismatch.\")\n",
    "                state_dict.pop(key)\n",
    "\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels, all_fitz = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, fitz in dataloader:\n",
    "            images, fitz = images.to(device), fitz.to(device)\n",
    "            outputs = model(images, fitz)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_fitz.extend(fitz.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    spec = recall_score(all_labels, all_preds, pos_label=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "    # Fitzpatrick group-wise accuracy\n",
    "    fitz_groups = {}\n",
    "    for pred, true, fitz in zip(all_preds, all_labels, all_fitz):\n",
    "        if fitz not in fitz_groups:\n",
    "            fitz_groups[fitz] = {'correct': 0, 'total': 0}\n",
    "        fitz_groups[fitz]['correct'] += int(pred == true)\n",
    "        fitz_groups[fitz]['total'] += 1\n",
    "\n",
    "    fitz_acc = {f\"Fitzpatrick {k}\": v['correct'] / v['total'] if v['total'] > 0 else 0.0 \n",
    "                for k, v in fitz_groups.items()}\n",
    "\n",
    "    return acc, cm, prec, rec, f1, spec, report, fitz_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dca2ef-9a8a-4ae2-a66d-8f9b63bcefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# 6. MAIN EVALUATION SCRIPT FOR BOTH DATASETS\n",
    "###############################################\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Evaluates both ViT and ResNet models on two datasets:\n",
    "    - PASSION (real validation split with Fitzpatrick scores)\n",
    "    - DermNet (domain-shifted test set with dummy Fitzpatrick info)\n",
    "    \n",
    "    Outputs classification and fairness metrics, confusion matrices, and saves results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pretrained model checkpoints and their readable labels\n",
    "    vit_model_files = [f\"vit_finetuned_optuna_09_04_2025.pth\"]\n",
    "    resnet_model_files = [f\"resnet_finetuned_optuna_09_04_2025.pth\"]\n",
    "    vit_labels = [\"ViT Finetuned Optuna\"]\n",
    "    resnet_labels = [\"ResNet Finetuned Optuna\"]\n",
    "\n",
    "    # Define datasets for testing (PASSION and DermNet)\n",
    "    datasets_info = [\n",
    "        (\"PASSION\", PassionDatasetBinary(\n",
    "            csv_file=passion_csv_path,\n",
    "            image_folder=passion_image_folder,\n",
    "            transform=valid_transforms,\n",
    "            mode=\"validation\"\n",
    "        )),\n",
    "        (\"DermNet\", DermNetDatasetBinary(\n",
    "            root=dermnet_unseen_root,\n",
    "            transform=valid_transforms\n",
    "        ))\n",
    "    ]\n",
    "\n",
    "    num_classes = 2\n",
    "    fitzpatrick_vocab_size = 7\n",
    "\n",
    "    for ds_name, dataset in datasets_info:\n",
    "        print(f\"\\n=== Evaluating on {ds_name} dataset ===\")\n",
    "        dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # --- ViT Evaluation ---\n",
    "        for model_file, label in zip(vit_model_files, vit_labels):\n",
    "            print(f\"\\nTesting {label} using checkpoint {model_file} ...\")\n",
    "            acc, cm, prec, rec, f1, spec, report, fitz_acc = evaluate_model(\n",
    "                ViTModelWithFitzpatrick, model_file, dataloader, num_classes, device, fitzpatrick_vocab_size\n",
    "            )\n",
    "            print(f\"{label} on {ds_name}:\")\n",
    "            print(f\"  Accuracy:    {acc:.4f}\")\n",
    "            print(f\"  Precision:   {prec:.4f}\")\n",
    "            print(f\"  Recall:      {rec:.4f}\")\n",
    "            print(f\"  F1 Score:    {f1:.4f}\")\n",
    "            print(f\"  Specificity: {spec:.4f}\")\n",
    "            print(\"  Fitzpatrick Group Accuracies:\")\n",
    "            for group, group_acc in fitz_acc.items():\n",
    "                print(f\"    {group}: {group_acc:.4f}\")\n",
    "\n",
    "            # Plot confusion matrix\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                        xticklabels=list(dataset.label_map.values()),\n",
    "                        yticklabels=list(dataset.label_map.values()))\n",
    "            plt.title(f\"Confusion Matrix - {label} on {ds_name}\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"confusion_matrix_{label.replace(' ', '_')}_{ds_name}.png\", dpi=300)\n",
    "            plt.show()\n",
    "\n",
    "        # --- ResNet Evaluation ---\n",
    "        for model_file, label in zip(resnet_model_files, resnet_labels):\n",
    "            print(f\"\\nTesting {label} using checkpoint {model_file} ...\")\n",
    "            acc, cm, prec, rec, f1, spec, report, fitz_acc = evaluate_model(\n",
    "                ResNet50ModelWithFitzpatrick, model_file, dataloader, num_classes, device, fitzpatrick_vocab_size\n",
    "            )\n",
    "            print(f\"{label} on {ds_name}:\")\n",
    "            print(f\"  Accuracy:    {acc:.4f}\")\n",
    "            print(f\"  Precision:   {prec:.4f}\")\n",
    "            print(f\"  Recall:      {rec:.4f}\")\n",
    "            print(f\"  F1 Score:    {f1:.4f}\")\n",
    "            print(f\"  Specificity: {spec:.4f}\")\n",
    "            print(\"  Fitzpatrick Group Accuracies:\")\n",
    "            for group, group_acc in fitz_acc.items():\n",
    "                print(f\"    {group}: {group_acc:.4f}\")\n",
    "\n",
    "            # Plot confusion matrix\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                        xticklabels=list(dataset.label_map.values()),\n",
    "                        yticklabels=list(dataset.label_map.values()))\n",
    "            plt.title(f\"Confusion Matrix - {label} on {ds_name}\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"confusion_matrix_{label.replace(' ', '_')}_{ds_name}.png\", dpi=300)\n",
    "            plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a719a5c-cf4d-489c-86da-4dbc539c89fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Baseline ViT Model Training (Without Fairness Embedding)\n",
    "--------------------------------------------------------\n",
    "\n",
    "This script trains a baseline Vision Transformer (ViT) model for binary eczema classification\n",
    "using the PASSION dataset. It excludes fairness-aware features such as Fitzpatrick skin type \n",
    "embedding, serving as a control/baseline for comparison against fairness-integrated models.\n",
    "\n",
    "Key Features:\n",
    "- Binary label generation: Eczema vs. Non-Eczema\n",
    "- Image augmentation pipeline using RandAugment and ColorJitter\n",
    "- StratifiedGroupKFold for patient-wise split to prevent data leakage\n",
    "- Early stopping based on validation loss\n",
    "- Model saving with timestamp for reproducibility\n",
    "\n",
    "Notes:\n",
    "- This model excludes Fitzpatrick skin tone information.\n",
    "- A similar version of this script can be used for ResNet by replacing the ViT model class \n",
    "  with `ResNet50ModelWithFitzpatrick` (excluding the fairness embedding).\n",
    "- This baseline is useful for measuring the effect of fairness-aware training components \n",
    "  in more advanced experiments.\n",
    "\n",
    "Dependencies: PyTorch, torchvision, timm, sklearn, pandas, numpy, OpenCV\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Set device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "###############################################\n",
    "# 1. HYPERPARAMETERS & PATHS\n",
    "###############################################\n",
    "lr = 1e-5\n",
    "weight_decay = 1e-2\n",
    "dropout_rate = 0.2\n",
    "num_epochs_finetune = 15\n",
    "patience_finetune = 3\n",
    "freeze_epochs_passion = 5\n",
    "\n",
    "# Dataset paths\n",
    "dermnet_train_root = r\"C:\\Users\\DermNet\\train\"\n",
    "passion_csv_path = r\"C:\\Users\\PASSION_MICCAI_2024\\label.csv\"\n",
    "passion_image_folder = r\"C:\\Users\\PASSION_MICCAI_2024\\images\"\n",
    "\n",
    "###############################################\n",
    "# 2. CSV SPLITTING FOR PASSION\n",
    "###############################################\n",
    "df_full = pd.read_csv(passion_csv_path)\n",
    "df_full.columns = df_full.columns.str.strip()\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in sgkf.split(df_full, df_full[\"conditions_PASSION\"], groups=df_full[\"subject_id\"]):\n",
    "    train_df = df_full.iloc[train_idx]\n",
    "    val_df = df_full.iloc[val_idx]\n",
    "    break\n",
    "train_csv = \"train_split.csv\"\n",
    "val_csv = \"val_split.csv\"\n",
    "train_df.to_csv(train_csv, index=False)\n",
    "val_df.to_csv(val_csv, index=False)\n",
    "\n",
    "###############################################\n",
    "# 3. IMAGE TRANSFORMATIONS\n",
    "###############################################\n",
    "class DADATransform:\n",
    "    def __init__(self, num_ops=2, magnitude=9):\n",
    "        self.augment = transforms.RandAugment(num_ops=num_ops, magnitude=magnitude)\n",
    "    def __call__(self, img):\n",
    "        return self.augment(img)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    DADATransform(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "###############################################\n",
    "# 4. DATASET CLASS DEFINITIONS\n",
    "###############################################\n",
    "class PassionDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None, mode=\"train\"):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.data[\"binary_label\"] = self.data[\"conditions_PASSION\"].apply(\n",
    "            lambda x: 1 if str(x).strip().lower() == \"eczema\" else 0)\n",
    "        self.image_files = []\n",
    "        for subject_id in self.data[\"subject_id\"]:\n",
    "            subject_imgs = glob.glob(os.path.join(image_folder, f\"{subject_id}_*.jpg\"))\n",
    "            self.image_files.extend([(img, subject_id) for img in subject_imgs])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, subject_id = self.image_files[idx]\n",
    "        row = self.data[self.data[\"subject_id\"] == subject_id]\n",
    "        label = int(row[\"binary_label\"].values[0])\n",
    "        fitz = int(row[\"fitzpatrick\"].values[0])  # Not used in this model\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long), torch.tensor(fitz, dtype=torch.long)\n",
    "\n",
    "###############################################\n",
    "# 5. DATALOADERS\n",
    "###############################################\n",
    "passion_train_ds = PassionDataset(train_csv, passion_image_folder, transform=train_transforms)\n",
    "passion_val_ds = PassionDataset(val_csv, passion_image_folder, transform=valid_transforms)\n",
    "train_loader = DataLoader(passion_train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(passion_val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "###############################################\n",
    "# 6. BASELINE MODEL: ViT WITHOUT FAIRNESS\n",
    "###############################################\n",
    "class ViTWithoutFitz(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        in_features = self.vit.head.in_features\n",
    "        self.vit.head = nn.Identity()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        vit_features = self.vit(x)\n",
    "        return self.classifier(vit_features)\n",
    "\n",
    "###############################################\n",
    "# 7. TRAINING FUNCTION (NO FAIRNESS)\n",
    "###############################################\n",
    "def train_model_nofair(model, train_loader, val_loader, device,\n",
    "                       num_epochs=5, freeze_epochs=0, patience=2, lr=1e-5):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    if freeze_epochs > 0:\n",
    "        for param in model.vit.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for images, labels, _ in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch == freeze_epochs:\n",
    "            for param in model.vit.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=(num_epochs - freeze_epochs))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels, _ in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"vit_nofairness_best.pth\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                break\n",
    "\n",
    "###############################################\n",
    "# 8. EXECUTE TRAINING\n",
    "###############################################\n",
    "vit_nofair = ViTWithoutFitz(num_classes=2).to(device)\n",
    "train_model_nofair(vit_nofair, train_loader, val_loader, device,\n",
    "                   num_epochs=num_epochs_finetune,\n",
    "                   freeze_epochs=freeze_epochs_passion,\n",
    "                   patience=patience_finetune,\n",
    "                   lr=lr)\n",
    "\n",
    "torch.save(vit_nofair.state_dict(), \"vit_nofairness_best_22APR2025.pth\")\n",
    "print(\" Model re-saved as vit_nofairness_best_22APR2025.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85643bc-8a96-4c5f-8e5e-16cc2215570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# ROC Curve Plotting for Model Comparison\n",
    "###############################################\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(model, loader, label, color):\n",
    "    \"\"\"\n",
    "    Plots the ROC curve for a given model and dataloader.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model to evaluate.\n",
    "        loader: DataLoader for the evaluation dataset.\n",
    "        label: Label to use in the plot legend.\n",
    "        color: Line color for the plot.\n",
    "\n",
    "    Returns:\n",
    "        AUC score (float).\n",
    "    \"\"\"\n",
    "    model.to(device).eval()\n",
    "    y_true, y_scores = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, fitz in loader:\n",
    "            imgs, fitz = imgs.to(device), fitz.to(device)\n",
    "            outputs = model(imgs, fitz)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1 (eczema)\n",
    "            y_scores.extend(probs.cpu().numpy())\n",
    "            y_true.extend(labels.numpy())\n",
    "\n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "    return roc_auc\n",
    "###############################################\n",
    "# Initialize Models & Load Checkpoints\n",
    "###############################################\n",
    "\n",
    "# Ensure these model classes are already defined:\n",
    "# - ViTModelWithFitzpatrick\n",
    "# - ResNet50ModelWithFitzpatrick\n",
    "\n",
    "# Instantiate models\n",
    "vit_model = ViTModelWithFitzpatrick(num_classes=2, fitzpatrick_vocab_size=7)\n",
    "resnet_model = ResNet50ModelWithFitzpatrick(num_classes=2, fitzpatrick_vocab_size=7)\n",
    "\n",
    "# Load trained model weights (Optuna-tuned checkpoints)\n",
    "vit_model.load_state_dict(torch.load(\"vit_finetuned_optuna_09_04_2025.pth\", map_location=device), strict=False)\n",
    "resnet_model.load_state_dict(torch.load(\"resnet_finetuned_optuna_09_04_2025.pth\", map_location=device), strict=False)\n",
    "###############################################\n",
    "# Plot ROC Curves for Both Models\n",
    "###############################################\n",
    "\n",
    "# 'loader' must be defined beforehand and contain the test or validation dataset\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot ViT ROC\n",
    "vit_auc = plot_roc_curve(vit_model, loader, label=\"ViT\", color=\"dimgray\")\n",
    "\n",
    "# Plot ResNet ROC\n",
    "resnet_auc = plot_roc_curve(resnet_model, loader, label=\"ResNet\", color=\"gray\")\n",
    "\n",
    "# Plot random chance baseline\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "\n",
    "# Labels and styling\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve: ViT vs ResNet (Optuna-Tuned)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display the figure\n",
    "plt.savefig(\"roc_comparison_vit_vs_resnet.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274e37a-6441-4207-9341-7fa5db8de1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation Script: Calibration, Statistical Testing, and Fairness Assessment\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "This script evaluates two pretrained binary eczema classification models:\n",
    "- Vision Transformer (ViT)\n",
    "- ResNet-50\n",
    "\n",
    "It performs a comprehensive analysis across multiple evaluation dimensions:\n",
    "1. Classification performance (F1 score, Recall, AUC, Brier score)\n",
    "2. Statistical significance testing using McNemar’s test\n",
    "3. Confidence interval estimation of AUC differences via bootstrapping\n",
    "4. Calibration assessment and correction using Temperature Scaling\n",
    "5. Fairness analysis based on:\n",
    "   - Demographic Parity (DP)\n",
    "   - Equalized Odds (EO)\n",
    "\n",
    "Usage Requirements:\n",
    "- Provide trained model checkpoint paths (Optuna-tuned .pth files)\n",
    "- Ensure availability of a compatible DataLoader (`loader`) using the `PassionDatasetBinary` class\n",
    "- Verify `valid_transforms` is defined and used for preprocessing\n",
    "- This script assumes binary classification: eczema vs. non-eczema\n",
    "\n",
    "Note:\n",
    "- Although the script is centered on evaluating ViT, ResNet evaluation is included.\n",
    "- All methods are generalizable; similar analysis can be extended to additional models.\n",
    "\n",
    "Dependencies: PyTorch, torchvision, timm, sklearn, matplotlib, scipy, numpy\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1e129-f229-4360-b9ac-61649ecc71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# Model Definitions (ViT and ResNet with fairness embedding)\n",
    "###############################################\n",
    "class ViTFair(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
    "        feat = self.vit.head.in_features\n",
    "        self.vit.head = nn.Identity()\n",
    "        self.emb = nn.Embedding(7, 32)  # Fitzpatrick scale embedding\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feat + 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, fitz):\n",
    "        f = self.vit(x)\n",
    "        e = self.emb(fitz)\n",
    "        return self.classifier(torch.cat([f, e], dim=1))\n",
    "\n",
    "\n",
    "class ResNetFair(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.res = models.resnet50(pretrained=False)\n",
    "        feat = self.res.fc.in_features\n",
    "        self.res.fc = nn.Identity()\n",
    "        self.emb = nn.Embedding(7, 32)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feat + 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, fitz):\n",
    "        f = self.res(x)\n",
    "        e = self.emb(fitz)\n",
    "        return self.classifier(torch.cat([f, e], dim=1))\n",
    "###############################################\n",
    "# Evaluation Helpers\n",
    "###############################################\n",
    "def evaluate_preds(model, loader):\n",
    "    \"\"\"\n",
    "    Runs inference and returns labels, predictions, probabilities, and metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    labs, preds, probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, y, fitz in loader:\n",
    "            imgs, fitz = imgs.to(device), fitz.to(device)\n",
    "            out = model(imgs, fitz)\n",
    "            p = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
    "            labs.extend(y.numpy())\n",
    "            preds.extend((p >= 0.5).astype(int))\n",
    "            probs.extend(p)\n",
    "\n",
    "    a = np.array(labs)\n",
    "    b = np.array(preds)\n",
    "    c = np.array(probs)\n",
    "    return a, b, c, {\n",
    "        \"f1\": f1_score(a, b),\n",
    "        \"recall\": recall_score(a, b),\n",
    "        \"auc\": roc_auc_score(a, c),\n",
    "        \"brier\": brier_score_loss(a, c)\n",
    "    }\n",
    "###############################################\n",
    "# Model Loading & Evaluation\n",
    "###############################################\n",
    "models_info = {\n",
    "    \"ViT\": (ViTFair, \"vit_finetuned_optuna_09_04_2025.pth\"),\n",
    "    \"ResNet\": (ResNetFair, \"resnet_finetuned_optuna_09_04_2025.pth\")\n",
    "}\n",
    "\n",
    "results, arrays = {}, {}\n",
    "\n",
    "for name, (Cls, ckpt) in models_info.items():\n",
    "    model = Cls().to(device)\n",
    "    state = torch.load(ckpt, map_location=device, weights_only=True)\n",
    "\n",
    "    # Rename weights for compatibility\n",
    "    if \"fitz_emb.weight\" in state:\n",
    "        state[\"emb.weight\"] = state.pop(\"fitz_emb.weight\")\n",
    "    for old, new in [(\"classifier.3.weight\", \"classifier.2.weight\"),\n",
    "                     (\"classifier.3.bias\", \"classifier.2.bias\")]:\n",
    "        if old in state:\n",
    "            state[new] = state.pop(old)\n",
    "    if name == \"ResNet\":\n",
    "        state = {k.replace(\"resnet.\", \"res.\"): v for k, v in state.items()}\n",
    "\n",
    "    model.load_state_dict(state, strict=True)\n",
    "    l, p, q, m = evaluate_preds(model, loader)\n",
    "    results[name] = m\n",
    "    arrays[name] = (l, p, q)\n",
    "    print(f\"{name} → {m}\")\n",
    "\n",
    "###############################################\n",
    "# McNemar’s Test for Statistical Comparison\n",
    "###############################################\n",
    "from scipy.stats import chi2\n",
    "\n",
    "lv, pv, _ = arrays[\"ViT\"]\n",
    "lr, pr, _ = arrays[\"ResNet\"]\n",
    "assert np.array_equal(lv, lr)\n",
    "\n",
    "N01 = np.sum((pv == lv) & (pr != lv))\n",
    "N10 = np.sum((pv != lv) & (pr == lv))\n",
    "n = N01 + N10\n",
    "\n",
    "if n == 0:\n",
    "    print(\"No discordant pairs.\")\n",
    "else:\n",
    "    chi2_stat = (abs(N10 - N01) - 1)**2 / n\n",
    "    p_val = 1 - chi2.cdf(chi2_stat, df=1)\n",
    "    print(f\"McNemar’s χ²={chi2_stat:.3f}, p={p_val:.4e}  (b={N10}, c={N01})\")\n",
    "\n",
    "###############################################\n",
    "# AUC Confidence Interval via Bootstrapping\n",
    "###############################################\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "diffs = []\n",
    "rng = np.random.default_rng(0)\n",
    "n = len(lv)\n",
    "\n",
    "for _ in range(2000):\n",
    "    idx = rng.integers(0, n, n)\n",
    "    auc_v = roc_auc_score(lv[idx], arrays[\"ViT\"][2][idx])\n",
    "    auc_r = roc_auc_score(lv[idx], arrays[\"ResNet\"][2][idx])\n",
    "    diffs.append(auc_v - auc_r)\n",
    "\n",
    "ci_low, ci_high = np.percentile(diffs, [2.5, 97.5])\n",
    "print(f\"AUC difference (ViT–ResNet): {results['ViT']['auc'] - results['ResNet']['auc']:.4f}\")\n",
    "print(f\"95% CI: [{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "\n",
    "###############################################\n",
    "# Temperature Scaling for Calibration\n",
    "###############################################\n",
    "import torch.nn.functional as F\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "class TemperatureScaler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "\n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature\n",
    "\n",
    "def temperature_scale(model, logits, labels):\n",
    "    model.eval()\n",
    "    temp_model = TemperatureScaler().to(device)\n",
    "    optimizer = torch.optim.LBFGS([temp_model.temperature], lr=0.01, max_iter=50)\n",
    "\n",
    "    def loss_fn():\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(temp_model(logits), labels)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(loss_fn)\n",
    "    return temp_model.temperature.item()\n",
    "\n",
    "def apply_temperature(logits, T):\n",
    "    return logits / T\n",
    "\n",
    "def evaluate_calibration(logits, labels):\n",
    "    probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "    return brier_score_loss(labels.cpu().numpy(), probs)\n",
    "\n",
    "print(\"\\n--- Temperature Scaling Calibration ---\")\n",
    "for name, (Cls, ckpt) in models_info.items():\n",
    "    model = Cls().to(device)\n",
    "    state = torch.load(ckpt, map_location=device, weights_only=True)\n",
    "    if \"fitz_emb.weight\" in state:\n",
    "        state[\"emb.weight\"] = state.pop(\"fitz_emb.weight\")\n",
    "    for old, new in [(\"classifier.3.weight\", \"classifier.2.weight\"),\n",
    "                     (\"classifier.3.bias\", \"classifier.2.bias\")]:\n",
    "        if old in state:\n",
    "            state[new] = state.pop(old)\n",
    "    if name == \"ResNet\":\n",
    "        state = {k.replace(\"resnet.\", \"res.\"): v for k, v in state.items()}\n",
    "    model.load_state_dict(state, strict=True)\n",
    "    model.eval()\n",
    "\n",
    "    logits, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labs, fitz in loader:\n",
    "            imgs, labs, fitz = imgs.to(device), labs.to(device), fitz.to(device)\n",
    "            out = model(imgs, fitz)\n",
    "            logits.append(out)\n",
    "            labels.append(labs)\n",
    "    logits = torch.cat(logits)\n",
    "    labels = torch.cat(labels)\n",
    "\n",
    "    brier_before = evaluate_calibration(logits, labels)\n",
    "    T = temperature_scale(model, logits, labels)\n",
    "    logits_scaled = apply_temperature(logits, T)\n",
    "    brier_after = evaluate_calibration(logits_scaled, labels)\n",
    "\n",
    "    print(f\"\\n{name} - Optimal Temp: {T:.4f}\")\n",
    "    print(f\"Brier Score Before: {brier_before:.4f}\")\n",
    "    print(f\"Brier Score After : {brier_after:.4f}\")\n",
    "\n",
    "    # Generate calibration curve (optional, for reporting only)\n",
    "    probs_scaled = torch.softmax(logits_scaled, dim=1)[:, 1].cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    prob_true, prob_pred = calibration_curve(labels_np, probs_scaled, n_bins=10)\n",
    "\n",
    "    # Plot calibration curve\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(prob_pred, prob_true, label=f\"{name} (T={T:.2f})\", lw=2)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly Calibrated\")\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Empirical Accuracy\")\n",
    "    plt.title(f\"Calibration Curve After Temperature Scaling – {name}\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{name.lower()}_calibration_temp_scaled.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "###############################################\n",
    "# Fairness Metrics (DP & EO)\n",
    "###############################################\n",
    "def fairness_metrics(labels, preds, groups):\n",
    "    labels, preds, groups = np.array(labels), np.array(preds), np.array(groups)\n",
    "    groups_unique = np.unique(groups)\n",
    "\n",
    "    # Demographic Parity (DP)\n",
    "    positive_rates = [preds[groups == g].mean() for g in groups_unique]\n",
    "    dp_diff = np.abs(max(positive_rates) - min(positive_rates))\n",
    "\n",
    "    # Equalized Odds (EO)\n",
    "    tpr_rates = []\n",
    "    for g in groups_unique:\n",
    "        mask = (groups == g) & (labels == 1)\n",
    "        if mask.sum() > 0:\n",
    "            tpr_rates.append(preds[mask].mean())\n",
    "    eo_diff = np.abs(max(tpr_rates) - min(tpr_rates))\n",
    "\n",
    "    return dp_diff, eo_diff\n",
    "\n",
    "print(\"\\n--- Fairness Metrics ---\")\n",
    "for name in models_info.keys():\n",
    "    l, p, _ = arrays[name]\n",
    "    fitz_groups = np.clip(dataset.data[\"fitzpatrick\"].values, 0, 6)\n",
    "    dp, eo = fairness_metrics(l, p, fitz_groups)\n",
    "    print(f\"\\n{name} - Demographic Parity Diff: {dp:.4f}\")\n",
    "    print(f\"{name} - Equalized Odds Diff: {eo:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
